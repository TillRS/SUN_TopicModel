{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample use of the sun topic model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sun_topicmodel import suntopic\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a 10000 by 250 dataframe df_x with some numeric values and some NaNs\n",
    "# generate a matching Y with some nan values\n",
    "np.random.seed(0)\n",
    "x_df = pd.DataFrame(np.random.randn(1000, 250))\n",
    "x_df[x_df < 0] = np.nan\n",
    "y_df = np.random.randn(1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features:\n",
      "Index([4, 25, 43, 68, 156, 182, 188, 189, 209, 212], dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Assuming x_df and y_df are your dataframes\n",
    "# x_df should contain your features and y_df should contain your target variable\n",
    "\n",
    "# Impute missing values in x_df\n",
    "imputer = SimpleImputer(strategy='mean')  # You can choose other strategies as well\n",
    "x_imputed = imputer.fit_transform(x_df)\n",
    "\n",
    "# Feature selection using SelectKBest\n",
    "k = 10  # Number of top features to select\n",
    "selector = SelectKBest(score_func=f_regression, k=k)\n",
    "x_selected = selector.fit_transform(x_imputed, y_df)\n",
    "\n",
    "# Get the indices of the selected features\n",
    "selected_feature_indices = selector.get_support(indices=True)\n",
    "\n",
    "# Get the names of the selected features\n",
    "selected_feature_names = x_df.columns[selected_feature_indices]\n",
    "\n",
    "# Print the names of selected features\n",
    "print(\"Selected Features:\")\n",
    "print(selected_feature_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "(slice(None, None, None), [1])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 24\u001b[0m\n\u001b[1;32m     21\u001b[0m     best_feature_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;66;03m# Fit the regressor with current selected features\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m     reg\u001b[38;5;241m.\u001b[39mfit(\u001b[43mX_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mselected_features\u001b[49m\u001b[43m]\u001b[49m, y_train)\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;66;03m# Calculate RMSE on test set\u001b[39;00m\n\u001b[1;32m     27\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m reg\u001b[38;5;241m.\u001b[39mpredict(X_test[:, selected_features])\n",
      "File \u001b[0;32m~/micromamba/envs/cftext/lib/python3.11/site-packages/pandas/core/frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3760\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3761\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3763\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/micromamba/envs/cftext/lib/python3.11/site-packages/pandas/core/indexes/range.py:349\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Hashable):\n\u001b[0;32m--> 349\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[1;32m    350\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: (slice(None, None, None), [1])"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Assuming X is your feature matrix and y is your continuous target vector\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_df, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the regressor\n",
    "reg = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Initialize the selected features list\n",
    "selected_features = []\n",
    "\n",
    "# Perform incremental feature selection\n",
    "for i in range(X_train.shape[1]):  # Iterate over the number of features\n",
    "    # Check if selected_features is empty\n",
    "    if not selected_features:\n",
    "        # Add the first feature to selected_features\n",
    "        best_feature_index = 0\n",
    "    else:\n",
    "        # Fit the regressor with current selected features\n",
    "        reg.fit(X_train[:, selected_features], y_train)\n",
    "    \n",
    "        # Calculate RMSE on test set\n",
    "        y_pred = reg.predict(X_test[:, selected_features])\n",
    "        # rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "    \n",
    "        print(f\"Iteration {i+1}: RMSE with {len(selected_features)} features: {rmse}\")\n",
    "    \n",
    "        # Get feature importances\n",
    "        feature_importances = reg.feature_importances_\n",
    "    \n",
    "        # Select the feature with the highest importance\n",
    "        best_feature_index = feature_importances.argmax()\n",
    "    \n",
    "    # Add the best feature to the selected features list\n",
    "    selected_features.append(best_feature_index)\n",
    "\n",
    "# Print the final selected features\n",
    "print(\"Final selected features:\", selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_x_copy = df_x.copy()\n",
    "# df_y_copy = df_y.copy()\n",
    "\n",
    "# X = np.array(df_x_copy.dropna())\n",
    "# Y = np.array(df_y[df_x_copy.index()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use feature selection on the columns of df_x\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# Generate a 10000 by 250 dataframe df_x with some numeric values and some NaNs\n",
    "# generate a matching Y with some nan values\n",
    "np.random.seed(0)\n",
    "df_x = pd.DataFrame(np.random.randn(1000, 250))\n",
    "# df_x[df_x < 0] = np.nan\n",
    "df_y = np.random.randn(1000)\n",
    "\n",
    "X = np.array(df_x)\n",
    "y = df_y\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384.2978492768443"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate random data as the 'embeddings' for the 'documents' in the corpus\n",
    "np.random.seed(2024)\n",
    "n = 2000\n",
    "m = 500\n",
    "J = 10\n",
    "W_t = np.random.rand(n, J)\n",
    "H_t = np.random.rand(J, m)\n",
    "X = np.dot(W_t, H_t) + np.random.rand(n, m) * 0.1\n",
    "coef_true = np.random.normal(0, 1, J)\n",
    "Y = np.dot(W_t, coef_true) + np.random.rand(n) * 0.1\n",
    "print(f\"coeff_true: {coef_true}\")\n",
    "\n",
    "sorted_indices = np.argsort(np.abs(coef_true))[::-1]\n",
    "sorted_coef_true = coef_true[sorted_indices]\n",
    "\n",
    "# Set font to Computer Modern\n",
    "plt.rcParams[\"text.usetex\"] = True\n",
    "\n",
    "# Plot the parameters\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "\n",
    "for i, param in enumerate(sorted_coef_true):\n",
    "    ax.axhline(i, color=\"gray\", linestyle=\"--\", linewidth=0.5, alpha=0.5)\n",
    "    ax.scatter(param, i, marker=\"x\", s=15, color=\"blue\", zorder=10)\n",
    "\n",
    "\n",
    "# Customize the plot\n",
    "ax.axvline(0, color=\"black\", linestyle=\"--\", linewidth=1)  # Add a vertical line at x=0\n",
    "ax.yaxis.tick_left()\n",
    "ax.invert_yaxis()  # Flip the graph\n",
    "ax.set_yticks(np.arange(len(sorted_coef_true)))\n",
    "ax.set_yticklabels([f\"({i+1})\" for i in sorted_indices], fontsize=12)\n",
    "ax.set_xlabel(\"True Effects\", fontsize=12)\n",
    "ax.set_title(\"True Effects sorted by absolute value\", fontsize=14)\n",
    "\n",
    "# Save or show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do train, estimation split\n",
    "X_train = X[:1500, :]\n",
    "X_est = X[1500:, :]\n",
    "Y_train = Y[:1500]\n",
    "Y_est = Y[1500:]\n",
    "\n",
    "# Initialize and fit the model\n",
    "model = suntopic(Y=Y_train, X=X_train, alpha=0.5, num_bases=3, random_state=2024)\n",
    "model.fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Y_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Initialize and fit the model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m suntopic(Y\u001b[38;5;241m=\u001b[39m\u001b[43mY_train\u001b[49m, X\u001b[38;5;241m=\u001b[39mX_train, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, num_bases\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2024\u001b[39m)\n\u001b[1;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39mfit()\n\u001b[1;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Y_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Initialize and fit the model\n",
    "model = suntopic(Y=Y_train, X=X_train, alpha=0.1, num_bases=3, random_state=2024)\n",
    "model.fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use cross validation for finding optimal hyperparameters: number of bases and alpha\n",
    "model.hyperparam_cv(\n",
    "    alpha_range=np.linspace(0.1, 0.9, 9),\n",
    "    num_bases_range=np.arange(2, 10),\n",
    "    cv_folds=5,\n",
    "    random_state=2024,\n",
    ")\n",
    "model.cv_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use parallelization to speed up the hyperparameter search\n",
    "model.hyperparam_cv(\n",
    "    alpha_range=np.linspace(0.1, 0.9, 9),\n",
    "    num_bases_range=np.arange(2, 12),\n",
    "    cv_folds=5,\n",
    "    random_state=2024,\n",
    "    parallel=True,\n",
    ")\n",
    "model.cv_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cv_mse_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and fit the model with best hyperparameters\n",
    "model = suntopic(Y=Y_train, X=X_train, alpha=0.4, num_bases=8, random_state=2024)\n",
    "model.fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimate AMCE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_est_pred, W_est = model.predict(X_est, return_topics=True, random_state=2024)\n",
    "print(f\"{W_est.shape = }\")\n",
    "\n",
    "# Fit a linear regression model to the estimated topics\n",
    "W_est = sm.add_constant(W_est)\n",
    "model_est = sm.OLS(Y_est, W_est).fit()\n",
    "print(model_est.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "\n",
    "\n",
    "# Set font to Computer Modern\n",
    "rc(\"font\", **{\"family\": \"serif\", \"serif\": [\"Computer Modern\"]})\n",
    "plt.rcParams[\"text.usetex\"] = True\n",
    "\n",
    "# Extract parameters and confidence intervals from the regression results\n",
    "params = model_est.params[1:]\n",
    "conf_int = model_est.conf_int()[1:]\n",
    "\n",
    "# Plot the parameters\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "\n",
    "for i, (param, (lower, upper)) in enumerate(zip(params, conf_int)):\n",
    "    # Add horizontal lines between rows\n",
    "    ax.axhline(i, color=\"gray\", linestyle=\"--\", linewidth=0.5, alpha=0.5)\n",
    "\n",
    "    if lower <= 0 & 0 <= upper:\n",
    "        ax.plot(\n",
    "            [lower, upper],\n",
    "            [i, i],\n",
    "            color=\"lightgray\",\n",
    "            linewidth=6,\n",
    "            solid_capstyle=\"butt\",\n",
    "            alpha=0.7,\n",
    "        )\n",
    "        ax.scatter(param, i, marker=\"o\", s=6, color=\"black\", zorder=10)\n",
    "\n",
    "    elif lower <= 0 & 0 >= upper:\n",
    "        ax.plot(\n",
    "            [lower, upper],\n",
    "            [i, i],\n",
    "            color=\"red\",\n",
    "            linewidth=6,\n",
    "            solid_capstyle=\"butt\",\n",
    "            alpha=0.3,\n",
    "        )\n",
    "        ax.scatter(param, i, marker=\"o\", s=6, color=\"black\", zorder=10)\n",
    "\n",
    "    else:\n",
    "        ax.plot(\n",
    "            [lower, upper],\n",
    "            [i, i],\n",
    "            color=\"green\",\n",
    "            linewidth=6,\n",
    "            solid_capstyle=\"butt\",\n",
    "            alpha=0.3,\n",
    "        )\n",
    "        ax.scatter(param, i, marker=\"o\", s=6, color=\"black\", zorder=10)\n",
    "\n",
    "# Customize the plot\n",
    "ax.axvline(0, color=\"black\", linestyle=\"--\", linewidth=1)  # Add a vertical line at x=0\n",
    "ax.yaxis.tick_left()\n",
    "ax.invert_yaxis()  # Flip the graph\n",
    "ax.set_yticks(np.arange(len(params)))\n",
    "ax.set_yticklabels([f\"({i+1})\" for i in range(len(model_est.params) - 1)], fontsize=12)\n",
    "ax.set_xlabel(\"Estimated Effects\", fontsize=12)\n",
    "# include lin break in the title\n",
    "ax.set_title(\"Estimates of Topic Effects with 95\\% Confidence Intervals\", fontsize=14)\n",
    "\n",
    "\n",
    "# Save or show the plot\n",
    "plt.tight_layout()\n",
    "# plt.savefig( str(data_dir) + '/LinWood_Causal_Effects_plot2.png',bbox_inches=\"tight\", dpi=600)  # Save the plot as an image file\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
